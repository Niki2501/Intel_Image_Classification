{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## INTEL IMAGE CLASSIFICATION"
      ],
      "metadata": {
        "id": "CilNBc0WQ4Rt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd9Q74Wcz-w7",
        "outputId": "6702e7cc-08a8-4c10-a6a5-067f4476f75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#connecting google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5KqIEbiGKsL"
      },
      "outputs": [],
      "source": [
        "#IMPORTING FILE FROM KAGGLE\n",
        "#Go to Kaggle profice .... Scroll down ... There's API.....You'll get username and password from there\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"nikki2501\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"18a26daea5b258038f4b2a03cdfee09f\" # key from the json file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading Kaggle dataset\n",
        "!kaggle datasets download -d puneet6060/intel-image-classification"
      ],
      "metadata": {
        "id": "VaBuP980hgxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2ad25c-2425-4f8d-a796-d1e5a97a21ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading intel-image-classification.zip to /content\n",
            "100% 345M/346M [00:02<00:00, 126MB/s]\n",
            "100% 346M/346M [00:02<00:00, 123MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcQiZzdoGYCB",
        "outputId": "55f0a88d-5d81-408b-9525-b68ef1140455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# Unzip training data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/intel-image-classification.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URZ7hRdsGZNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b905082f-26b0-4bb7-bc39-095145feb172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install split-folders\n",
        "#this library is used to divide data to train test n val "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv9cIXZtGapL"
      },
      "outputs": [],
      "source": [
        "#IMPORTING necessary Libraries\n",
        "# from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D,Dropout,GlobalAveragePooling2D\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "# import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread\n",
        "import pathlib\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26hpeV8eGdeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21010ed2-33df-4430-c2ca-2a7dea783007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 14034 files [00:02, 5692.01 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "splitfolders.ratio(\"/content/seg_train/seg_train\", output=\"FINAL\",\n",
        "    # seed=1337, \n",
        "    ratio=(.8, .2), group_prefix=None, move=False) # default values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_wB50ToGe9j"
      },
      "outputs": [],
      "source": [
        "#Mentioning path to all directories\n",
        "train_dir ='/content/FINAL/train'\n",
        "val_dir = '/content/FINAL/val'\n",
        "test_dir ='/content/seg_test/seg_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrYCOV08GgzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc26dcde-ef91-4557-e533-58c8189387b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mountain', 'street', 'forest', 'glacier', 'buildings', 'sea']\n"
          ]
        }
      ],
      "source": [
        "#Checking the class labels of train directory\n",
        "labels = os.listdir(train_dir)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts8D44JAGiU8"
      },
      "outputs": [],
      "source": [
        "#defining image size and batch size (batch size is Number of samples per batch of computation )\n",
        "img_width=331\n",
        "img_height=331\n",
        "batch_size=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWSrDPzlGj5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c827e09-2a44-4bf9-fbc3-07b6b939ee08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11224 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "#ImageDataGenerator is used Generate batches of tensor image data with real-time data augmentation.\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "                                  #  rotation_range=30,rescale = 1/255,\n",
        "                                  #  zoom_range=0.4,\n",
        "                                  #  horizontal_flip=True)\n",
        "#all the above commented can be when we have to augment the images\n",
        "#flow_from_directory Takes the path to a directory, and generates batches of augmented/normalized data\n",
        "#to understand more about flow_from_directory refer this: https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/\n",
        "#class_mode : One of \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\".\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(img_height, img_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Npph2r9rGlYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27488f2-ef1b-4bdf-8122-64996822cec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)#rescale = 1/255\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  target_size=(img_height, img_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc9eJoA9GnNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f8b438-f699-4461-8e87-96e68787ab39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2810 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(val_dir,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 target_size=(img_height, img_width))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_dir= \"/content/drive/MyDrive/Inference/Inference Data(DX)\""
      ],
      "metadata": {
        "id": "07pbU29XOJNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inf_datagen = ImageDataGenerator(rescale = 1./255)#rescale = 1/255\n",
        "\n",
        "inf_generator = inf_datagen.flow_from_directory(inference_dir,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  target_size=(img_height, img_width))"
      ],
      "metadata": {
        "id": "OXPrNAxeOJKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ee80de-b823-46ea-e3b7-8a95d37cba4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3004 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW3r_KasTP7U"
      },
      "outputs": [],
      "source": [
        "# def scale_image(img,label):\n",
        "#   img = tf.cast(img,tf.float32)\n",
        "#   img = img/255.0\n",
        "#   img = tf.image.resize(img, (331,331))\n",
        "#   return img,label "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FROM here ownwards we start to use Keras models\n",
        "to know in deep about the models refer this : https://keras.io/api/applications/"
      ],
      "metadata": {
        "id": "FHdJI9alSCr1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2oDWWYb2Y8c"
      },
      "source": [
        "## **NasNetLarge**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScxkTRIVGorM"
      },
      "outputs": [],
      "source": [
        "from keras.applications.nasnet import NASNetLarge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST9JFTeZGs5r"
      },
      "outputs": [],
      "source": [
        "input_shape=(331,331,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task. using transfer learning.... imports model from it's stored location. no need to write each and every layer\n",
        "\n",
        "include_top false means because the fully connected layers at the end can only take fixed size inputs, which has been previously defined by the input shape and all processing in the convolutional layers. Any change to the input shape will change the shape of the input to the fully connected layers, making the weights incompatible (matrix sizes don't match and cannot be applied).\n",
        "\n",
        "Imagenet weights is used for images classification,transfer learning model models use the imagenet weights"
      ],
      "metadata": {
        "id": "PeUk3GXeSVgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHVzveRvGvOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69197851-e4d0-49ff-ba76-9038ab9e9d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n",
            "343610240/343610240 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#transfer learning used , explained above\n",
        "base = NASNetLarge(input_shape,\n",
        "                        include_top=False,\n",
        "                        weights='imagenet')\n",
        "\n",
        "base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2XXzJEzoBgE"
      },
      "outputs": [],
      "source": [
        "#Adding layers to our model, pooling it\n",
        "#Then mentioning number of classes we have(6 in this dataset)\n",
        "\n",
        "inputs = keras.Input(shape=(331,331,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDjVLLrE_a_9"
      },
      "outputs": [],
      "source": [
        "#Compiling the model \n",
        "#optimizer is used to reduce the losses\n",
        "#different type of metric explained here :\"https://keras.io/api/metrics/\"\n",
        "#Losses : The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting the model on daatset and traing our machine, Train_gen and val_gen gives the accuracy by which it works and epochs means how many number of time it gonna run to model again and again\n",
        "model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ],
      "metadata": {
        "id": "RcHY9mG7hF_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving model in .h5 file \n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/NasNetLarge.h5')"
      ],
      "metadata": {
        "id": "FMvWDZ0TBoHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rW6NFHitNgj",
        "outputId": "50b65367-cb43-4788-c9d4-0a9b85c6cb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 105s 4s/step - loss: 1.7335 - categorical_accuracy: 0.2197\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7335163354873657, 0.21966665983200073]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#checking the accuracy of test dataset\n",
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = keras.models.load_model('/content/drive/MyDrive/NasNetLarge.h5')"
      ],
      "metadata": {
        "id": "GROMdSoMOJQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the accuracy of inference dataset\n",
        "new_model.evaluate(inf_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSxULMglYO9a",
        "outputId": "4e5fabc1-7c54-4bd0-843e-cb94179c1b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 886s 37s/step - loss: 1.0159 - categorical_accuracy: 0.7713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0159363746643066, 0.7713049054145813]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Same model with 30epochs"
      ],
      "metadata": {
        "id": "rkws0F-RS4BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "model.fit(train_generator, epochs=30, validation_data=val_generator)"
      ],
      "metadata": {
        "id": "_Ua68yKCOI1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc04ac80-5e99-402d-928c-5768fcbc21e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "88/88 [==============================] - 448s 5s/step - loss: 0.4235 - categorical_accuracy: 0.8579 - val_loss: 0.2851 - val_categorical_accuracy: 0.9007\n",
            "Epoch 2/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.2360 - categorical_accuracy: 0.9138 - val_loss: 0.2630 - val_categorical_accuracy: 0.9096\n",
            "Epoch 3/30\n",
            "88/88 [==============================] - 421s 5s/step - loss: 0.2081 - categorical_accuracy: 0.9228 - val_loss: 0.2509 - val_categorical_accuracy: 0.9117\n",
            "Epoch 4/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1914 - categorical_accuracy: 0.9300 - val_loss: 0.2377 - val_categorical_accuracy: 0.9192\n",
            "Epoch 5/30\n",
            "88/88 [==============================] - 421s 5s/step - loss: 0.1789 - categorical_accuracy: 0.9342 - val_loss: 0.2346 - val_categorical_accuracy: 0.9142\n",
            "Epoch 6/30\n",
            "88/88 [==============================] - 421s 5s/step - loss: 0.1673 - categorical_accuracy: 0.9383 - val_loss: 0.2337 - val_categorical_accuracy: 0.9189\n",
            "Epoch 7/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1593 - categorical_accuracy: 0.9435 - val_loss: 0.2293 - val_categorical_accuracy: 0.9174\n",
            "Epoch 8/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1527 - categorical_accuracy: 0.9446 - val_loss: 0.2293 - val_categorical_accuracy: 0.9192\n",
            "Epoch 9/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1453 - categorical_accuracy: 0.9485 - val_loss: 0.2302 - val_categorical_accuracy: 0.9185\n",
            "Epoch 10/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1411 - categorical_accuracy: 0.9517 - val_loss: 0.2296 - val_categorical_accuracy: 0.9185\n",
            "Epoch 11/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1354 - categorical_accuracy: 0.9522 - val_loss: 0.2305 - val_categorical_accuracy: 0.9185\n",
            "Epoch 12/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1300 - categorical_accuracy: 0.9555 - val_loss: 0.2268 - val_categorical_accuracy: 0.9174\n",
            "Epoch 13/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.1260 - categorical_accuracy: 0.9563 - val_loss: 0.2269 - val_categorical_accuracy: 0.9174\n",
            "Epoch 14/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.1232 - categorical_accuracy: 0.9591 - val_loss: 0.2292 - val_categorical_accuracy: 0.9196\n",
            "Epoch 15/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.1183 - categorical_accuracy: 0.9591 - val_loss: 0.2300 - val_categorical_accuracy: 0.9171\n",
            "Epoch 16/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.1162 - categorical_accuracy: 0.9587 - val_loss: 0.2322 - val_categorical_accuracy: 0.9174\n",
            "Epoch 17/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.1130 - categorical_accuracy: 0.9620 - val_loss: 0.2326 - val_categorical_accuracy: 0.9178\n",
            "Epoch 18/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.1094 - categorical_accuracy: 0.9631 - val_loss: 0.2345 - val_categorical_accuracy: 0.9171\n",
            "Epoch 19/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1067 - categorical_accuracy: 0.9636 - val_loss: 0.2342 - val_categorical_accuracy: 0.9185\n",
            "Epoch 20/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1036 - categorical_accuracy: 0.9651 - val_loss: 0.2312 - val_categorical_accuracy: 0.9171\n",
            "Epoch 21/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.1014 - categorical_accuracy: 0.9667 - val_loss: 0.2352 - val_categorical_accuracy: 0.9203\n",
            "Epoch 22/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.0995 - categorical_accuracy: 0.9661 - val_loss: 0.2372 - val_categorical_accuracy: 0.9171\n",
            "Epoch 23/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.0972 - categorical_accuracy: 0.9664 - val_loss: 0.2399 - val_categorical_accuracy: 0.9171\n",
            "Epoch 24/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.0956 - categorical_accuracy: 0.9685 - val_loss: 0.2395 - val_categorical_accuracy: 0.9171\n",
            "Epoch 25/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.0937 - categorical_accuracy: 0.9692 - val_loss: 0.2364 - val_categorical_accuracy: 0.9174\n",
            "Epoch 26/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.0915 - categorical_accuracy: 0.9702 - val_loss: 0.2365 - val_categorical_accuracy: 0.9174\n",
            "Epoch 27/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.0906 - categorical_accuracy: 0.9691 - val_loss: 0.2412 - val_categorical_accuracy: 0.9164\n",
            "Epoch 28/30\n",
            "88/88 [==============================] - 420s 5s/step - loss: 0.0880 - categorical_accuracy: 0.9710 - val_loss: 0.2422 - val_categorical_accuracy: 0.9160\n",
            "Epoch 29/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.0859 - categorical_accuracy: 0.9721 - val_loss: 0.2443 - val_categorical_accuracy: 0.9164\n",
            "Epoch 30/30\n",
            "88/88 [==============================] - 419s 5s/step - loss: 0.0849 - categorical_accuracy: 0.9722 - val_loss: 0.2436 - val_categorical_accuracy: 0.9171\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a3dffb5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/NasNetLarge_30epochs.h5')"
      ],
      "metadata": {
        "id": "quFhg-5kdxtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "7xO2xiZiOIyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc9c910-9fae-4605-c065-c487c5f93f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 93s 4s/step - loss: 0.2202 - categorical_accuracy: 0.9203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22016750276088715, 0.9203333258628845]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(inf_generator)"
      ],
      "metadata": {
        "id": "TIQ5zooRd7RG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3d3a5e-a299-4067-c130-01ee8c47959d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 133s 5s/step - loss: 1.3642 - categorical_accuracy: 0.7630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3641738891601562, 0.7629826664924622]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying different models , checking the accuracy and saving :"
      ],
      "metadata": {
        "id": "OsP7oBXETCLc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwIGOXe-nJ0z"
      },
      "source": [
        "#**NasNetMobile**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4k7tk_hSLc8"
      },
      "outputs": [],
      "source": [
        "from keras.applications.nasnet import NASNetMobile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfx-GmzpSOCA"
      },
      "outputs": [],
      "source": [
        "input_shape=(224,224,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2n_COtySV4-",
        "outputId": "d9edd460-5670-4f28-a290-e97d2a5bd1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile.h5\n",
            "24227760/24227760 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base = NASNetMobile(    input_shape=None,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1IBZxEApL1a"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(224,224,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON5rM-7vScdy"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ckKjTzy3z65"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB4-mdKn2-9P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6PO5PHBcFJW"
      },
      "source": [
        "# InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "772AGPt7bvYt"
      },
      "outputs": [],
      "source": [
        "from keras.applications import InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ipJs2Wqb2YL"
      },
      "outputs": [],
      "source": [
        "base=InceptionV3 (\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFT4-qXeb6H1"
      },
      "outputs": [],
      "source": [
        "base.trainable = False\n",
        "inputs = keras.Input(shape=(299,299,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSdDpzdab-e7",
        "outputId": "16f59372-c08f-4451-9c03-2933b5ccbfa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vjISE-S5LUH",
        "outputId": "3d5a7d27-a473-4385-ff53-81ae69e27c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "88/88 [==============================] - 87s 876ms/step - loss: 1.7676 - categorical_accuracy: 0.4735 - val_loss: 1.7359 - val_categorical_accuracy: 0.6843\n",
            "Epoch 2/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 1.7069 - categorical_accuracy: 0.7177 - val_loss: 1.6771 - val_categorical_accuracy: 0.7370\n",
            "Epoch 3/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.6491 - categorical_accuracy: 0.7511 - val_loss: 1.6208 - val_categorical_accuracy: 0.7495\n",
            "Epoch 4/100\n",
            "88/88 [==============================] - 65s 737ms/step - loss: 1.5937 - categorical_accuracy: 0.7564 - val_loss: 1.5669 - val_categorical_accuracy: 0.7616\n",
            "Epoch 5/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 1.5405 - categorical_accuracy: 0.7692 - val_loss: 1.5154 - val_categorical_accuracy: 0.7751\n",
            "Epoch 6/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.4899 - categorical_accuracy: 0.7831 - val_loss: 1.4661 - val_categorical_accuracy: 0.7751\n",
            "Epoch 7/100\n",
            "88/88 [==============================] - 65s 737ms/step - loss: 1.4415 - categorical_accuracy: 0.7875 - val_loss: 1.4191 - val_categorical_accuracy: 0.7808\n",
            "Epoch 8/100\n",
            "88/88 [==============================] - 66s 750ms/step - loss: 1.3953 - categorical_accuracy: 0.7899 - val_loss: 1.3743 - val_categorical_accuracy: 0.7836\n",
            "Epoch 9/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 1.3512 - categorical_accuracy: 0.7981 - val_loss: 1.3317 - val_categorical_accuracy: 0.7875\n",
            "Epoch 10/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.3092 - categorical_accuracy: 0.7933 - val_loss: 1.2910 - val_categorical_accuracy: 0.7932\n",
            "Epoch 11/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 1.2692 - categorical_accuracy: 0.8020 - val_loss: 1.2526 - val_categorical_accuracy: 0.7943\n",
            "Epoch 12/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.2313 - categorical_accuracy: 0.8028 - val_loss: 1.2159 - val_categorical_accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.1954 - categorical_accuracy: 0.8041 - val_loss: 1.1812 - val_categorical_accuracy: 0.8021\n",
            "Epoch 14/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.1611 - categorical_accuracy: 0.8070 - val_loss: 1.1482 - val_categorical_accuracy: 0.8018\n",
            "Epoch 15/100\n",
            "88/88 [==============================] - 65s 741ms/step - loss: 1.1286 - categorical_accuracy: 0.8050 - val_loss: 1.1170 - val_categorical_accuracy: 0.8039\n",
            "Epoch 16/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.0978 - categorical_accuracy: 0.8085 - val_loss: 1.0873 - val_categorical_accuracy: 0.8043\n",
            "Epoch 17/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 1.0686 - categorical_accuracy: 0.8083 - val_loss: 1.0593 - val_categorical_accuracy: 0.8057\n",
            "Epoch 18/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 1.0408 - categorical_accuracy: 0.8085 - val_loss: 1.0326 - val_categorical_accuracy: 0.8060\n",
            "Epoch 19/100\n",
            "88/88 [==============================] - 65s 742ms/step - loss: 1.0145 - categorical_accuracy: 0.8084 - val_loss: 1.0074 - val_categorical_accuracy: 0.8071\n",
            "Epoch 20/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.9895 - categorical_accuracy: 0.8087 - val_loss: 0.9834 - val_categorical_accuracy: 0.8078\n",
            "Epoch 21/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.9658 - categorical_accuracy: 0.8093 - val_loss: 0.9607 - val_categorical_accuracy: 0.8082\n",
            "Epoch 22/100\n",
            "88/88 [==============================] - 65s 737ms/step - loss: 0.9433 - categorical_accuracy: 0.8101 - val_loss: 0.9392 - val_categorical_accuracy: 0.8075\n",
            "Epoch 23/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.9219 - categorical_accuracy: 0.8104 - val_loss: 0.9188 - val_categorical_accuracy: 0.8050\n",
            "Epoch 24/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.9016 - categorical_accuracy: 0.8116 - val_loss: 0.8994 - val_categorical_accuracy: 0.8057\n",
            "Epoch 25/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.8823 - categorical_accuracy: 0.8128 - val_loss: 0.8810 - val_categorical_accuracy: 0.8053\n",
            "Epoch 26/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.8640 - categorical_accuracy: 0.8127 - val_loss: 0.8635 - val_categorical_accuracy: 0.8057\n",
            "Epoch 27/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.8465 - categorical_accuracy: 0.8132 - val_loss: 0.8470 - val_categorical_accuracy: 0.8068\n",
            "Epoch 28/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.8299 - categorical_accuracy: 0.8131 - val_loss: 0.8312 - val_categorical_accuracy: 0.8053\n",
            "Epoch 29/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.8141 - categorical_accuracy: 0.8137 - val_loss: 0.8162 - val_categorical_accuracy: 0.8057\n",
            "Epoch 30/100\n",
            "88/88 [==============================] - 66s 748ms/step - loss: 0.7990 - categorical_accuracy: 0.8133 - val_loss: 0.8019 - val_categorical_accuracy: 0.8068\n",
            "Epoch 31/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.7847 - categorical_accuracy: 0.8138 - val_loss: 0.7884 - val_categorical_accuracy: 0.8068\n",
            "Epoch 32/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.7710 - categorical_accuracy: 0.8142 - val_loss: 0.7754 - val_categorical_accuracy: 0.8064\n",
            "Epoch 33/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.7579 - categorical_accuracy: 0.8143 - val_loss: 0.7631 - val_categorical_accuracy: 0.8071\n",
            "Epoch 34/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.7454 - categorical_accuracy: 0.8150 - val_loss: 0.7513 - val_categorical_accuracy: 0.8068\n",
            "Epoch 35/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.7335 - categorical_accuracy: 0.8150 - val_loss: 0.7401 - val_categorical_accuracy: 0.8057\n",
            "Epoch 36/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.7221 - categorical_accuracy: 0.8150 - val_loss: 0.7294 - val_categorical_accuracy: 0.8060\n",
            "Epoch 37/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.7112 - categorical_accuracy: 0.8160 - val_loss: 0.7192 - val_categorical_accuracy: 0.8060\n",
            "Epoch 38/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.7008 - categorical_accuracy: 0.8159 - val_loss: 0.7094 - val_categorical_accuracy: 0.8071\n",
            "Epoch 39/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.6908 - categorical_accuracy: 0.8160 - val_loss: 0.7001 - val_categorical_accuracy: 0.8053\n",
            "Epoch 40/100\n",
            "88/88 [==============================] - 65s 741ms/step - loss: 0.6812 - categorical_accuracy: 0.8165 - val_loss: 0.6912 - val_categorical_accuracy: 0.8075\n",
            "Epoch 41/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.6720 - categorical_accuracy: 0.8161 - val_loss: 0.6826 - val_categorical_accuracy: 0.8068\n",
            "Epoch 42/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.6632 - categorical_accuracy: 0.8174 - val_loss: 0.6745 - val_categorical_accuracy: 0.8064\n",
            "Epoch 43/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.6547 - categorical_accuracy: 0.8175 - val_loss: 0.6666 - val_categorical_accuracy: 0.8075\n",
            "Epoch 44/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.6466 - categorical_accuracy: 0.8179 - val_loss: 0.6591 - val_categorical_accuracy: 0.8082\n",
            "Epoch 45/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.6388 - categorical_accuracy: 0.8177 - val_loss: 0.6519 - val_categorical_accuracy: 0.8082\n",
            "Epoch 46/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.6313 - categorical_accuracy: 0.8182 - val_loss: 0.6450 - val_categorical_accuracy: 0.8089\n",
            "Epoch 47/100\n",
            "88/88 [==============================] - 66s 746ms/step - loss: 0.6241 - categorical_accuracy: 0.8184 - val_loss: 0.6384 - val_categorical_accuracy: 0.8100\n",
            "Epoch 48/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.6172 - categorical_accuracy: 0.8188 - val_loss: 0.6320 - val_categorical_accuracy: 0.8100\n",
            "Epoch 49/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.6104 - categorical_accuracy: 0.8192 - val_loss: 0.6259 - val_categorical_accuracy: 0.8114\n",
            "Epoch 50/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.6040 - categorical_accuracy: 0.8192 - val_loss: 0.6200 - val_categorical_accuracy: 0.8110\n",
            "Epoch 51/100\n",
            "88/88 [==============================] - 65s 741ms/step - loss: 0.5978 - categorical_accuracy: 0.8196 - val_loss: 0.6143 - val_categorical_accuracy: 0.8100\n",
            "Epoch 52/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.5918 - categorical_accuracy: 0.8199 - val_loss: 0.6089 - val_categorical_accuracy: 0.8114\n",
            "Epoch 53/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5860 - categorical_accuracy: 0.8207 - val_loss: 0.6037 - val_categorical_accuracy: 0.8121\n",
            "Epoch 54/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.5804 - categorical_accuracy: 0.8209 - val_loss: 0.5986 - val_categorical_accuracy: 0.8125\n",
            "Epoch 55/100\n",
            "88/88 [==============================] - 65s 742ms/step - loss: 0.5750 - categorical_accuracy: 0.8213 - val_loss: 0.5937 - val_categorical_accuracy: 0.8128\n",
            "Epoch 56/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5698 - categorical_accuracy: 0.8215 - val_loss: 0.5890 - val_categorical_accuracy: 0.8142\n",
            "Epoch 57/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5648 - categorical_accuracy: 0.8226 - val_loss: 0.5845 - val_categorical_accuracy: 0.8132\n",
            "Epoch 58/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.5599 - categorical_accuracy: 0.8231 - val_loss: 0.5801 - val_categorical_accuracy: 0.8149\n",
            "Epoch 59/100\n",
            "88/88 [==============================] - 66s 744ms/step - loss: 0.5551 - categorical_accuracy: 0.8231 - val_loss: 0.5759 - val_categorical_accuracy: 0.8135\n",
            "Epoch 60/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5506 - categorical_accuracy: 0.8234 - val_loss: 0.5718 - val_categorical_accuracy: 0.8135\n",
            "Epoch 61/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.5461 - categorical_accuracy: 0.8239 - val_loss: 0.5679 - val_categorical_accuracy: 0.8146\n",
            "Epoch 62/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.5418 - categorical_accuracy: 0.8247 - val_loss: 0.5641 - val_categorical_accuracy: 0.8142\n",
            "Epoch 63/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.5377 - categorical_accuracy: 0.8255 - val_loss: 0.5605 - val_categorical_accuracy: 0.8157\n",
            "Epoch 64/100\n",
            "88/88 [==============================] - 65s 742ms/step - loss: 0.5336 - categorical_accuracy: 0.8261 - val_loss: 0.5569 - val_categorical_accuracy: 0.8167\n",
            "Epoch 65/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5297 - categorical_accuracy: 0.8262 - val_loss: 0.5535 - val_categorical_accuracy: 0.8178\n",
            "Epoch 66/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5259 - categorical_accuracy: 0.8268 - val_loss: 0.5501 - val_categorical_accuracy: 0.8178\n",
            "Epoch 67/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5221 - categorical_accuracy: 0.8274 - val_loss: 0.5469 - val_categorical_accuracy: 0.8199\n",
            "Epoch 68/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.5186 - categorical_accuracy: 0.8279 - val_loss: 0.5438 - val_categorical_accuracy: 0.8199\n",
            "Epoch 69/100\n",
            "88/88 [==============================] - 65s 737ms/step - loss: 0.5151 - categorical_accuracy: 0.8288 - val_loss: 0.5407 - val_categorical_accuracy: 0.8206\n",
            "Epoch 70/100\n",
            "88/88 [==============================] - 66s 746ms/step - loss: 0.5117 - categorical_accuracy: 0.8294 - val_loss: 0.5378 - val_categorical_accuracy: 0.8210\n",
            "Epoch 71/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.5083 - categorical_accuracy: 0.8296 - val_loss: 0.5349 - val_categorical_accuracy: 0.8221\n",
            "Epoch 72/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.5051 - categorical_accuracy: 0.8300 - val_loss: 0.5322 - val_categorical_accuracy: 0.8235\n",
            "Epoch 73/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.5020 - categorical_accuracy: 0.8302 - val_loss: 0.5295 - val_categorical_accuracy: 0.8246\n",
            "Epoch 74/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.4989 - categorical_accuracy: 0.8305 - val_loss: 0.5269 - val_categorical_accuracy: 0.8249\n",
            "Epoch 75/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4959 - categorical_accuracy: 0.8303 - val_loss: 0.5244 - val_categorical_accuracy: 0.8249\n",
            "Epoch 76/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4930 - categorical_accuracy: 0.8312 - val_loss: 0.5219 - val_categorical_accuracy: 0.8260\n",
            "Epoch 77/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4902 - categorical_accuracy: 0.8313 - val_loss: 0.5196 - val_categorical_accuracy: 0.8263\n",
            "Epoch 78/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.4874 - categorical_accuracy: 0.8321 - val_loss: 0.5172 - val_categorical_accuracy: 0.8267\n",
            "Epoch 79/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4847 - categorical_accuracy: 0.8326 - val_loss: 0.5150 - val_categorical_accuracy: 0.8270\n",
            "Epoch 80/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.4821 - categorical_accuracy: 0.8328 - val_loss: 0.5128 - val_categorical_accuracy: 0.8270\n",
            "Epoch 81/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.4795 - categorical_accuracy: 0.8329 - val_loss: 0.5107 - val_categorical_accuracy: 0.8281\n",
            "Epoch 82/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.4770 - categorical_accuracy: 0.8339 - val_loss: 0.5086 - val_categorical_accuracy: 0.8281\n",
            "Epoch 83/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4745 - categorical_accuracy: 0.8342 - val_loss: 0.5066 - val_categorical_accuracy: 0.8285\n",
            "Epoch 84/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4722 - categorical_accuracy: 0.8347 - val_loss: 0.5046 - val_categorical_accuracy: 0.8288\n",
            "Epoch 85/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4698 - categorical_accuracy: 0.8349 - val_loss: 0.5027 - val_categorical_accuracy: 0.8292\n",
            "Epoch 86/100\n",
            "88/88 [==============================] - 66s 744ms/step - loss: 0.4675 - categorical_accuracy: 0.8352 - val_loss: 0.5009 - val_categorical_accuracy: 0.8295\n",
            "Epoch 87/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4653 - categorical_accuracy: 0.8356 - val_loss: 0.4991 - val_categorical_accuracy: 0.8310\n",
            "Epoch 88/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.4631 - categorical_accuracy: 0.8359 - val_loss: 0.4973 - val_categorical_accuracy: 0.8310\n",
            "Epoch 89/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4610 - categorical_accuracy: 0.8365 - val_loss: 0.4956 - val_categorical_accuracy: 0.8302\n",
            "Epoch 90/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4589 - categorical_accuracy: 0.8366 - val_loss: 0.4939 - val_categorical_accuracy: 0.8320\n",
            "Epoch 91/100\n",
            "88/88 [==============================] - 65s 738ms/step - loss: 0.4568 - categorical_accuracy: 0.8378 - val_loss: 0.4923 - val_categorical_accuracy: 0.8313\n",
            "Epoch 92/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.4548 - categorical_accuracy: 0.8378 - val_loss: 0.4907 - val_categorical_accuracy: 0.8320\n",
            "Epoch 93/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4529 - categorical_accuracy: 0.8385 - val_loss: 0.4891 - val_categorical_accuracy: 0.8320\n",
            "Epoch 94/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.4509 - categorical_accuracy: 0.8382 - val_loss: 0.4876 - val_categorical_accuracy: 0.8331\n",
            "Epoch 95/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.4490 - categorical_accuracy: 0.8388 - val_loss: 0.4862 - val_categorical_accuracy: 0.8338\n",
            "Epoch 96/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4472 - categorical_accuracy: 0.8393 - val_loss: 0.4847 - val_categorical_accuracy: 0.8338\n",
            "Epoch 97/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4454 - categorical_accuracy: 0.8394 - val_loss: 0.4833 - val_categorical_accuracy: 0.8342\n",
            "Epoch 98/100\n",
            "88/88 [==============================] - 65s 740ms/step - loss: 0.4436 - categorical_accuracy: 0.8402 - val_loss: 0.4820 - val_categorical_accuracy: 0.8349\n",
            "Epoch 99/100\n",
            "88/88 [==============================] - 65s 739ms/step - loss: 0.4419 - categorical_accuracy: 0.8402 - val_loss: 0.4806 - val_categorical_accuracy: 0.8345\n",
            "Epoch 100/100\n",
            "88/88 [==============================] - 66s 744ms/step - loss: 0.4402 - categorical_accuracy: 0.8410 - val_loss: 0.4793 - val_categorical_accuracy: 0.8345\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ca5d1eb10>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "model.fit(train_generator, epochs=100, validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h8MllLicBAm",
        "outputId": "6bcab62d-f850-4737-f3fb-714936299655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 17s 714ms/step - loss: 0.4687 - categorical_accuracy: 0.8307\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.46870434284210205, 0.8306666612625122]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6in-mj0cV_A"
      },
      "source": [
        "## **ResNet152V2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWB75xiAdhcd"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet_v2 import ResNet152V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8NXwtm0dl6z"
      },
      "outputs": [],
      "source": [
        "input_shape=(224,224,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bycfs4-BdoKp"
      },
      "outputs": [],
      "source": [
        "base=ResNet152V2( input_shape,\n",
        "    # include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "base.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAk6TH7mdyen"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(224,224,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQmWAaIud3vf",
        "outputId": "254645cd-bdda-4b24-809a-3ae6b905337b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 236s 3s/step - loss: 1.7619 - categorical_accuracy: 0.5426 - val_loss: 1.7265 - val_categorical_accuracy: 0.7242\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.6937 - categorical_accuracy: 0.7414 - val_loss: 1.6603 - val_categorical_accuracy: 0.7569\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.6290 - categorical_accuracy: 0.7558 - val_loss: 1.5973 - val_categorical_accuracy: 0.7701\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.5676 - categorical_accuracy: 0.7684 - val_loss: 1.5374 - val_categorical_accuracy: 0.7754\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.5090 - categorical_accuracy: 0.7803 - val_loss: 1.4807 - val_categorical_accuracy: 0.7833\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 224s 3s/step - loss: 1.4536 - categorical_accuracy: 0.7839 - val_loss: 1.4269 - val_categorical_accuracy: 0.7836\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.4012 - categorical_accuracy: 0.7825 - val_loss: 1.3760 - val_categorical_accuracy: 0.7865\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.3517 - categorical_accuracy: 0.7884 - val_loss: 1.3280 - val_categorical_accuracy: 0.7883\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.3047 - categorical_accuracy: 0.7907 - val_loss: 1.2828 - val_categorical_accuracy: 0.7904\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 225s 3s/step - loss: 1.2606 - categorical_accuracy: 0.7907 - val_loss: 1.2401 - val_categorical_accuracy: 0.7929\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff88ec55a90>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG_Y9lp6d6hN",
        "outputId": "fc61835b-cf05-4452-fdd5-8aef4306c67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 49s 2s/step - loss: 1.2425 - categorical_accuracy: 0.7870\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.2425174713134766, 0.7870000004768372]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnneoLV3znmO",
        "outputId": "f13f5dad-106a-4d4a-ef8b-e3712cb96b64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 155). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/resnet152v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD3ko1DCgA4e"
      },
      "source": [
        "## **ResNet101**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDTY1pyugFRn"
      },
      "outputs": [],
      "source": [
        "from keras.applications import ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igjHniqdgDU9",
        "outputId": "665fe5e3-ea91-4fae-8960-366e5ba2d49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels.h5\n",
            "179648224/179648224 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base=ResNet101(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    # **kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vy6MpkqQ4rFo"
      },
      "outputs": [],
      "source": [
        "base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohihefZUnONK"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(224,224,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzNAxXhBnPWk"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7LdIViY6yf_",
        "outputId": "6c342204-80a0-44ad-e5e9-fd8759c4a4fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 189s 2s/step - loss: 1.7899 - categorical_accuracy: 0.2094 - val_loss: 1.7882 - val_categorical_accuracy: 0.1790\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 169s 2s/step - loss: 1.7870 - categorical_accuracy: 0.1826 - val_loss: 1.7855 - val_categorical_accuracy: 0.1804\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 169s 2s/step - loss: 1.7844 - categorical_accuracy: 0.1834 - val_loss: 1.7830 - val_categorical_accuracy: 0.1872\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 168s 2s/step - loss: 1.7819 - categorical_accuracy: 0.1916 - val_loss: 1.7805 - val_categorical_accuracy: 0.2021\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 169s 2s/step - loss: 1.7794 - categorical_accuracy: 0.2166 - val_loss: 1.7781 - val_categorical_accuracy: 0.2117\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 169s 2s/step - loss: 1.7769 - categorical_accuracy: 0.2050 - val_loss: 1.7756 - val_categorical_accuracy: 0.2295\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 169s 2s/step - loss: 1.7745 - categorical_accuracy: 0.2278 - val_loss: 1.7732 - val_categorical_accuracy: 0.2402\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 169s 2s/step - loss: 1.7721 - categorical_accuracy: 0.2306 - val_loss: 1.7708 - val_categorical_accuracy: 0.2537\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 169s 2s/step - loss: 1.7696 - categorical_accuracy: 0.2509 - val_loss: 1.7684 - val_categorical_accuracy: 0.2562\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 168s 2s/step - loss: 1.7673 - categorical_accuracy: 0.2586 - val_loss: 1.7661 - val_categorical_accuracy: 0.2569\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efde263c510>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iurhxmq-nR3W",
        "outputId": "1a19afbc-b7ce-4e0d-f0c6-4806eae4172c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 39s 2s/step - loss: 1.7649 - categorical_accuracy: 0.2423\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.7649445533752441, 0.2423333376646042]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4BF8qVQ4SBb"
      },
      "outputs": [],
      "source": [
        "   model.save('/content/drive/MyDrive/Colab Notebooks/resnet152v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMDkaAfC7LmU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUa0fb6z7Li7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te3USCJ47LgV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7BuSz67MEC"
      },
      "source": [
        "## **DenseNet169**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UjO7ZGU7P7S"
      },
      "outputs": [],
      "source": [
        "from keras.applications import DenseNet169"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nolOXc_g7Ofc"
      },
      "outputs": [],
      "source": [
        "base=DenseNet169(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9fnjkYH7YUU"
      },
      "outputs": [],
      "source": [
        "base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMYVLAdG7dqo"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(224,224,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUjSEIc27gdB"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMniSnGN7ieP",
        "outputId": "e38f6c4e-bec7-4f3e-e39f-6df844acc480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 142s 1s/step - loss: 1.7545 - categorical_accuracy: 0.5624 - val_loss: 1.7183 - val_categorical_accuracy: 0.6488\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 106s 1s/step - loss: 1.6868 - categorical_accuracy: 0.6709 - val_loss: 1.6524 - val_categorical_accuracy: 0.6694\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 106s 1s/step - loss: 1.6233 - categorical_accuracy: 0.6902 - val_loss: 1.5902 - val_categorical_accuracy: 0.6964\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 110s 1s/step - loss: 1.5629 - categorical_accuracy: 0.7210 - val_loss: 1.5314 - val_categorical_accuracy: 0.7185\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 108s 1s/step - loss: 1.5059 - categorical_accuracy: 0.7260 - val_loss: 1.4757 - val_categorical_accuracy: 0.7231\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 106s 1s/step - loss: 1.4521 - categorical_accuracy: 0.7296 - val_loss: 1.4235 - val_categorical_accuracy: 0.7324\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 106s 1s/step - loss: 1.4013 - categorical_accuracy: 0.7538 - val_loss: 1.3744 - val_categorical_accuracy: 0.7512\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 106s 1s/step - loss: 1.3537 - categorical_accuracy: 0.7616 - val_loss: 1.3280 - val_categorical_accuracy: 0.7580\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 106s 1s/step - loss: 1.3087 - categorical_accuracy: 0.7679 - val_loss: 1.2845 - val_categorical_accuracy: 0.7594\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 106s 1s/step - loss: 1.2663 - categorical_accuracy: 0.7651 - val_loss: 1.2437 - val_categorical_accuracy: 0.7658\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6419d5b90>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIrPc2ex7k99",
        "outputId": "94d2e04c-cdc7-469c-cdf9-9730387b0afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 29s 1s/step - loss: 1.2482 - categorical_accuracy: 0.7573\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.2482304573059082, 0.7573333382606506]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o8LpJ_d71ix",
        "outputId": "c977fb14-5d19-4345-bb15-ce60ea4c0034"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 168). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/DenseNet169')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfSmX1lq7585"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Ki81Du8_Qk"
      },
      "source": [
        "## **EfficientNetV2M**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQLg5Mu89FCn"
      },
      "outputs": [],
      "source": [
        "from keras.applications import EfficientNetV2M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhR7mm3L9EJe"
      },
      "outputs": [],
      "source": [
        "base= EfficientNetV2M(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "\n",
        "\n",
        "base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3b8QSnA9UHK"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(480,480,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km87byRG9UwF"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgAxed_f9XH6",
        "outputId": "22cafef4-34ac-41f1-eb13-62bd1cda0f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 230s 2s/step - loss: 1.7911 - categorical_accuracy: 0.1758 - val_loss: 1.7904 - val_categorical_accuracy: 0.1790\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 200s 2s/step - loss: 1.7902 - categorical_accuracy: 0.1790 - val_loss: 1.7897 - val_categorical_accuracy: 0.1790\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 200s 2s/step - loss: 1.7896 - categorical_accuracy: 0.1790 - val_loss: 1.7892 - val_categorical_accuracy: 0.1790\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 201s 2s/step - loss: 1.7890 - categorical_accuracy: 0.1790 - val_loss: 1.7886 - val_categorical_accuracy: 0.1790\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 201s 2s/step - loss: 1.7885 - categorical_accuracy: 0.1790 - val_loss: 1.7881 - val_categorical_accuracy: 0.1790\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 201s 2s/step - loss: 1.7879 - categorical_accuracy: 0.1790 - val_loss: 1.7876 - val_categorical_accuracy: 0.1790\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 201s 2s/step - loss: 1.7874 - categorical_accuracy: 0.1790 - val_loss: 1.7870 - val_categorical_accuracy: 0.1790\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 201s 2s/step - loss: 1.7869 - categorical_accuracy: 0.1790 - val_loss: 1.7865 - val_categorical_accuracy: 0.1790\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 201s 2s/step - loss: 1.7863 - categorical_accuracy: 0.1790 - val_loss: 1.7859 - val_categorical_accuracy: 0.1790\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 201s 2s/step - loss: 1.7857 - categorical_accuracy: 0.1790 - val_loss: 1.7854 - val_categorical_accuracy: 0.1790\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4d8eba850>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uudo2NT49bec",
        "outputId": "1320809a-5a7a-4b02-fcf8-2256f551a811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 46s 2s/step - loss: 1.7848 - categorical_accuracy: 0.1750\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.784754991531372, 0.17499999701976776]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKJqCHKP9ffp",
        "outputId": "ea625252-0406-480c-fa87-7a6466e5ae8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 245). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/EfficientNetV2M')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UFyFejYBXHp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGGY-gnZIvcz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vcLrgMIIzG7"
      },
      "source": [
        "## **xception**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P4D6JRtI2aa"
      },
      "outputs": [],
      "source": [
        "from keras.applications import Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BLiBjC9I07c"
      },
      "outputs": [],
      "source": [
        "base= Xception(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o688DjvEI89n"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(299,299,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pVlFCPwJBUD"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JlLHezaJETF",
        "outputId": "e18f0748-3cae-4c05-dd10-801a210547a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 161s 2s/step - loss: 1.7591 - categorical_accuracy: 0.5790 - val_loss: 1.7258 - val_categorical_accuracy: 0.7306\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 146s 2s/step - loss: 1.6955 - categorical_accuracy: 0.7431 - val_loss: 1.6635 - val_categorical_accuracy: 0.7847\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 147s 2s/step - loss: 1.6349 - categorical_accuracy: 0.7830 - val_loss: 1.6040 - val_categorical_accuracy: 0.7968\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 147s 2s/step - loss: 1.5770 - categorical_accuracy: 0.7878 - val_loss: 1.5473 - val_categorical_accuracy: 0.8014\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 147s 2s/step - loss: 1.5217 - categorical_accuracy: 0.7934 - val_loss: 1.4933 - val_categorical_accuracy: 0.8068\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 147s 2s/step - loss: 1.4693 - categorical_accuracy: 0.7985 - val_loss: 1.4418 - val_categorical_accuracy: 0.8043\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 147s 2s/step - loss: 1.4191 - categorical_accuracy: 0.7979 - val_loss: 1.3928 - val_categorical_accuracy: 0.8050\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 146s 2s/step - loss: 1.3716 - categorical_accuracy: 0.8027 - val_loss: 1.3463 - val_categorical_accuracy: 0.8043\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 147s 2s/step - loss: 1.3263 - categorical_accuracy: 0.8009 - val_loss: 1.3021 - val_categorical_accuracy: 0.8057\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 147s 2s/step - loss: 1.2835 - categorical_accuracy: 0.7992 - val_loss: 1.2603 - val_categorical_accuracy: 0.8036\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4cd41e250>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFIFIYJPJKsx",
        "outputId": "f3c55e36-3feb-4a63-ec78-12adb4947c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 31s 1s/step - loss: 1.2611 - categorical_accuracy: 0.7890\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.261128306388855, 0.7889999747276306]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q_iVp96J5iP",
        "outputId": "8b7f1cb3-83f0-462a-f0a3-7453ec85761f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/xception_1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VMwg-_NRnPj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CzluK6-pT-5"
      },
      "source": [
        "## **MobileNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRdv9oP6pXW3"
      },
      "outputs": [],
      "source": [
        "from keras.applications import MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cZA9TNepWEY",
        "outputId": "3e4eb93e-43fb-4873-9edb-68a72b76ff69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base=MobileNet(\n",
        "    # input_shape=None,\n",
        "    alpha=1.0,\n",
        "    depth_multiplier=1,\n",
        "    dropout=0.001,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    # **kwargs\n",
        ")\n",
        "base.trainable= False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BixHmV7pqwC"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(224,224,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icrBMOekprWq"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX6nAytjp8M9",
        "outputId": "4b68d127-4d75-43ef-a51b-400436224b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 50s 529ms/step - loss: 1.7543 - categorical_accuracy: 0.5375 - val_loss: 1.7151 - val_categorical_accuracy: 0.7128\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 38s 435ms/step - loss: 1.6809 - categorical_accuracy: 0.7270 - val_loss: 1.6438 - val_categorical_accuracy: 0.7552\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 39s 444ms/step - loss: 1.6119 - categorical_accuracy: 0.7576 - val_loss: 1.5766 - val_categorical_accuracy: 0.7797\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 38s 434ms/step - loss: 1.5468 - categorical_accuracy: 0.7675 - val_loss: 1.5131 - val_categorical_accuracy: 0.7904\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 38s 433ms/step - loss: 1.4854 - categorical_accuracy: 0.7775 - val_loss: 1.4533 - val_categorical_accuracy: 0.7947\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 39s 439ms/step - loss: 1.4273 - categorical_accuracy: 0.7808 - val_loss: 1.3967 - val_categorical_accuracy: 0.7829\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 38s 436ms/step - loss: 1.3726 - categorical_accuracy: 0.7894 - val_loss: 1.3437 - val_categorical_accuracy: 0.7872\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 38s 435ms/step - loss: 1.3212 - categorical_accuracy: 0.7840 - val_loss: 1.2938 - val_categorical_accuracy: 0.7872\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 39s 444ms/step - loss: 1.2728 - categorical_accuracy: 0.7888 - val_loss: 1.2469 - val_categorical_accuracy: 0.7890\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 39s 440ms/step - loss: 1.2275 - categorical_accuracy: 0.7867 - val_loss: 1.2030 - val_categorical_accuracy: 0.7893\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efa1ea54b90>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGl9OlAop_FC",
        "outputId": "3f9b18fe-cae1-45af-be41-b4ffdee66fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 10s 393ms/step - loss: 1.2090 - categorical_accuracy: 0.7690\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.209046483039856, 0.7689999938011169]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xc7nxBLqBai",
        "outputId": "c775cdf4-cfda-4d17-8880-2bee093add9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 28). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/MobileNet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bSNM5GKqFUr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYiHKfepscaH"
      },
      "source": [
        "#**EfficientNetB2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXA9CSoXsjhO"
      },
      "outputs": [],
      "source": [
        "from keras.applications import EfficientNetB2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SvWOIdOsdI1",
        "outputId": "ffacb09c-1738-4fd8-aaeb-6bc78e807f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2.h5\n",
            "37432240/37432240 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base= EfficientNetB2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    # **kwargs\n",
        ")\n",
        "\n",
        "base.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxqbrykIs4uJ"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(260,260,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFUNJiy5s7s_"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvKvLJifs900",
        "outputId": "6e2eebb5-d014-4b2c-e375-ceb7dbf120e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "88/88 [==============================] - 98s 1s/step - loss: 1.7911 - categorical_accuracy: 0.1757 - val_loss: 1.7904 - val_categorical_accuracy: 0.1790\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 81s 915ms/step - loss: 1.7903 - categorical_accuracy: 0.1790 - val_loss: 1.7898 - val_categorical_accuracy: 0.1790\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 81s 918ms/step - loss: 1.7897 - categorical_accuracy: 0.1790 - val_loss: 1.7893 - val_categorical_accuracy: 0.1790\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 81s 914ms/step - loss: 1.7893 - categorical_accuracy: 0.1790 - val_loss: 1.7889 - val_categorical_accuracy: 0.1790\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 81s 914ms/step - loss: 1.7887 - categorical_accuracy: 0.1790 - val_loss: 1.7884 - val_categorical_accuracy: 0.1790\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 81s 914ms/step - loss: 1.7883 - categorical_accuracy: 0.1793 - val_loss: 1.7879 - val_categorical_accuracy: 0.1794\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 81s 914ms/step - loss: 1.7878 - categorical_accuracy: 0.1794 - val_loss: 1.7874 - val_categorical_accuracy: 0.1808\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 81s 915ms/step - loss: 1.7873 - categorical_accuracy: 0.1803 - val_loss: 1.7869 - val_categorical_accuracy: 0.1822\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 81s 914ms/step - loss: 1.7869 - categorical_accuracy: 0.1799 - val_loss: 1.7865 - val_categorical_accuracy: 0.1843\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 81s 914ms/step - loss: 1.7864 - categorical_accuracy: 0.1843 - val_loss: 1.7860 - val_categorical_accuracy: 0.1907\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc55379810>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hmuAh02s__a",
        "outputId": "1710fb7d-dc41-499e-ff03-ca74b1c73dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 19s 785ms/step - loss: 1.7855 - categorical_accuracy: 0.1843\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.7854835987091064, 0.18433333933353424]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyQCyPbxtKpT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF4sU1jAvekD"
      },
      "source": [
        "# **EfficientNetB3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKO8pac5vlTa"
      },
      "outputs": [],
      "source": [
        "from keras.applications import EfficientNetB3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHZ07C-OvfHW"
      },
      "outputs": [],
      "source": [
        "base =EfficientNetB3(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    # **kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdJBH0d6vy5m"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(300,300,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHAkqzLIv1Ic"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq9STSPAv19p"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er4hg4G-v7IV"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgMWzfBmwfmD"
      },
      "source": [
        "## **EfficientNetB4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOsIT2jZwjID"
      },
      "outputs": [],
      "source": [
        "from keras.applications import EfficientNetB4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQa3kxbGwVmv",
        "outputId": "5108e95d-5274-4f62-8cfe-8f08a0be8a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4.h5\n",
            "78864416/78864416 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base=EfficientNetB4(\n",
        "    # include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    # **kwargs\n",
        ")\n",
        "\n",
        "base.trainable-False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGWy0Dvjw2Mz"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(380,380,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf8Mv3BCx9aj"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLQTSC_CyB4d"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIPbdGTiyEv1"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwajlmj4yKuI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5kD6_NxE0Fz"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/all'\n",
        "check_point = ModelCheckpoint( filepath = path,\n",
        "                                          monitor = \" val_acc \" ,\n",
        "                                          mode = \" max \" ,\n",
        "                                          save_best_only = True ,\n",
        "                                          save_weights_only= True\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSGnqNN0E7oG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ-nFVjFQmCM"
      },
      "source": [
        "## **InceptionResNetV2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EXzEY63Qr5B"
      },
      "outputs": [],
      "source": [
        "from keras.applications import InceptionResNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX5vlaykQk-0"
      },
      "outputs": [],
      "source": [
        "base=InceptionResNetV2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    # classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "    # **kwargs\n",
        ")\n",
        "\n",
        "base.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IiiGmwdQ-Dk"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(380,380,3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEz6FiDsREvv"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxohJdJURFaF"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, \n",
        "          epochs=10, \n",
        "          validation_data=val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbOupdXIlkbS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}